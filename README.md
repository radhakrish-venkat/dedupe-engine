# Deduplication Engine

A high-performance, scalable deduplication engine built with Go, featuring variable-block chunking, intelligent caching, and microservices architecture.

## üöÄ Features

- **Variable-Block Chunking**: Uses content-defined chunking with Blake3 hashing for optimal deduplication
- **Intelligent Caching**: LRU cache with Cuckoo filter for fast duplicate detection
- **Microservices Architecture**: Distributed services for ingest, storage, and stream handling
- **Containerized**: Full Docker support with docker-compose for easy deployment
- **Database Integration**: CockroachDB for metadata storage with ACID compliance
- **Object Storage**: MinIO integration for scalable chunk storage
- **gRPC Communication**: High-performance inter-service communication
- **Production Ready**: Health checks, error handling, and monitoring

## üìä Performance Highlights

- **99.92% deduplication ratio** on repetitive content (10MB file ‚Üí 8KB unique)
- **640 chunks** processed from 5MB random data
- **Real-time streaming** with gRPC bidirectional communication
- **Sub-second response times** for duplicate detection

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Stream Handler ‚îÇ    ‚îÇ   Ingest Node   ‚îÇ    ‚îÇ Data Storage    ‚îÇ
‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ    ‚îÇ Node            ‚îÇ
‚îÇ ‚Ä¢ File Reading  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ ‚Ä¢ Chunking      ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ ‚Ä¢ Metadata DB   ‚îÇ
‚îÇ ‚Ä¢ gRPC Client   ‚îÇ    ‚îÇ ‚Ä¢ Deduplication ‚îÇ    ‚îÇ ‚Ä¢ Object Store  ‚îÇ
‚îÇ ‚Ä¢ Backup Stream ‚îÇ    ‚îÇ ‚Ä¢ Cache         ‚îÇ    ‚îÇ ‚Ä¢ Chunk Storage ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                                ‚ñº
                       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                       ‚îÇ   CockroachDB   ‚îÇ
                       ‚îÇ ‚Ä¢ Metadata      ‚îÇ
                       ‚îÇ ‚Ä¢ Chunk Index   ‚îÇ
                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                                ‚ñº
                       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                       ‚îÇ     MinIO       ‚îÇ
                       ‚îÇ ‚Ä¢ Chunk Storage ‚îÇ
                       ‚îÇ ‚Ä¢ Object Store  ‚îÇ
                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üõ†Ô∏è Technology Stack

- **Language**: Go 1.21+
- **Database**: CockroachDB (PostgreSQL-compatible)
- **Object Storage**: MinIO (S3-compatible)
- **Communication**: gRPC with Protocol Buffers
- **Containerization**: Docker & Docker Compose
- **Caching**: LRU Cache with Cuckoo Filter
- **Chunking**: Variable-block with Blake3 hashing

## üöÄ Quick Start

### Prerequisites

- Docker and Docker Compose
- Go 1.21+ (for development)
- Git

### 1. Clone the Repository

```bash
git clone https://github.com/radhakrish-venkat/dedupe-engine.git
cd dedupe-engine
```

### 2. Start the Services

```bash
docker-compose up -d
```

This will start:
- **CockroachDB**: Database for metadata storage
- **MinIO**: Object storage for chunks
- **Data Storage Node**: gRPC server for storage operations
- **Ingest Node**: gRPC server for backup processing

### 3. Test the System

```bash
# Test with a small file
docker run --rm --network dedupe-engine_dedupe-net \
  -v $(pwd):/data dedupe-engine-stream-handler \
  -file /data/test-file.txt -ingest-addr ingest-node:50051
```

### 4. Monitor Services

```bash
# Check service status
docker-compose ps

# View logs
docker-compose logs -f ingest-node
```

## üìÅ Project Structure

```
dedupe-engine/
‚îú‚îÄ‚îÄ cmd/                    # Application entry points
‚îÇ   ‚îú‚îÄ‚îÄ data-storage-node/ # Storage service
‚îÇ   ‚îú‚îÄ‚îÄ ingest-node/       # Backup processing service
‚îÇ   ‚îî‚îÄ‚îÄ stream-handler/    # File reading client
‚îú‚îÄ‚îÄ internal/              # Internal packages
‚îÇ   ‚îú‚îÄ‚îÄ cache/            # LRU cache implementation
‚îÇ   ‚îú‚îÄ‚îÄ chunking/         # Variable-block chunking
‚îÇ   ‚îú‚îÄ‚îÄ db/              # Database operations
‚îÇ   ‚îî‚îÄ‚îÄ minio/           # Object storage client
‚îú‚îÄ‚îÄ pkg/                  # Public packages
‚îÇ   ‚îî‚îÄ‚îÄ api/             # gRPC protocol definitions
‚îú‚îÄ‚îÄ docker-compose.yml    # Service orchestration
‚îú‚îÄ‚îÄ Dockerfile.*         # Container definitions
‚îî‚îÄ‚îÄ README.md           # This file
```

## üîß Development

### Building from Source

```bash
# Build all services
go build ./cmd/data-storage-node
go build ./cmd/ingest-node
go build ./cmd/stream-handler

# Run tests
go test ./internal/...
```

### Running Tests

```bash
# Test chunking
go test ./internal/chunking

# Test caching
go test ./internal/cache

# Test database operations
go test ./internal/db
```

## üìä Testing Results

### File Type Testing

| File Type | Size | Deduplication | Chunks | Result |
|-----------|------|---------------|--------|---------|
| Text (unique) | 28B | 0% | 1 | ‚úÖ Expected |
| Text (edited) | 46B | 0% | 1 | ‚úÖ Expected |
| Small binary | 32B | 0% | 1 | ‚úÖ Expected |
| Large binary | 5MB | 0% | 640 | ‚úÖ Expected |
| Compressed (.zip) | 204B | 0% | 3 | ‚úÖ Expected |
| Compressed (.gz) | 60B | 0% | 1 | ‚úÖ Expected |
| Repetitive | 10MB | 99.92% | 1280 | ‚úÖ Excellent |

### Performance Metrics

- **Chunking Speed**: ~10MB/s
- **Deduplication Ratio**: Up to 99.92% on repetitive content
- **Cache Hit Rate**: >95% for duplicate detection
- **Storage Efficiency**: Significant space savings on similar files

## üîç API Reference

### gRPC Services

#### BackupService (Ingest Node)
```protobuf
service BackupService {
  rpc StreamBackup(stream BackupRequest) returns (stream BackupResponse);
}
```

#### StorageService (Data Storage Node)
```protobuf
service StorageService {
  rpc StoreChunk(StoreChunkRequest) returns (StoreChunkResponse);
  rpc RetrieveChunk(RetrieveChunkRequest) returns (RetrieveChunkResponse);
}
```

### Configuration

#### Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `COCKROACH_HOST` | `localhost` | CockroachDB host |
| `COCKROACH_PORT` | `26257` | CockroachDB port |
| `MINIO_ENDPOINT` | `localhost:9000` | MinIO endpoint |
| `MINIO_ACCESS_KEY` | `minioadmin` | MinIO access key |
| `MINIO_SECRET_KEY` | `minioadmin` | MinIO secret key |

## üê≥ Docker

### Building Images

```bash
# Build all images
docker-compose build

# Build specific service
docker build -f Dockerfile.ingest -t dedupe-engine-ingest-node .
```

### Running with Docker Compose

```bash
# Start all services
docker-compose up -d

# Stop all services
docker-compose down

# View logs
docker-compose logs -f
```

## üîí Security

- **Authentication**: MinIO access keys for object storage
- **Encryption**: Support for encrypted backups (planned)
- **Network**: Isolated Docker network for inter-service communication
- **Database**: CockroachDB with TLS support (configurable)

## üìà Monitoring

### Health Checks

All services include health check endpoints:

```bash
# Check service health
curl http://localhost:8080/health  # CockroachDB
curl http://localhost:9000/minio/health/live  # MinIO
```

### Metrics

- Chunks processed per second
- Deduplication ratio
- Cache hit/miss rates
- Storage utilization

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- **CockroachDB** for the distributed database
- **MinIO** for S3-compatible object storage
- **gRPC** for high-performance communication
- **Blake3** for fast cryptographic hashing

## üìû Support

- **Issues**: [GitHub Issues](https://github.com/radhakrish-venkat/dedupe-engine/issues)
- **Discussions**: [GitHub Discussions](https://github.com/radhakrish-venkat/dedupe-engine/discussions)
- **Documentation**: [GitHub Pages](https://radhakrish-venkat.github.io/dedupe-engine/)

---

**Built with ‚ù§Ô∏è using Go, Docker, and modern cloud technologies.** 